### 文件系统

文件系统通常由操作系统提供，而数据库如果没有直接访问磁盘的权限的话，通常是在文件系统之上实现的（注，早期数据库通常直接基于磁盘构建自己的文件系统，因为早期操作系统自带的文件系统在性能上较差，且写入不是同步的，进而导致数据库的ACID不能保证。不过现代操作系统自带的文件系统已经足够好，所以现代的数据库大部分构建在操作系统自带的文件系统之上）。

**文件系统结构**
虽然说法有很多，但是本质上就是
物理内存->缓冲区->文件组织模块->虚拟（逻辑）文件系统->用户程序


（补充：磁盘分为block和sector，sector是磁盘可以读取的最小单元，block是操作系统或者文件系统的单元，一般可以是多个sector，在xv6里是1024字节）


磁盘上的第一个盘块为boot sector，即引导区。一般来说每个磁盘可以划分成多个分区，而每个分区都会有一个引导区，如果在这个分区上安装有操作系统的话，需要将操作系统的引导入口写入到boot sector中。xv6默认磁盘只有一个分区，因此自然也就只有一个引导区。boot sector怎么将内核代码加载到内存中就又是另一个话题了，这里不再赘述。

磁盘的第二个盘块为super block，记录着管理这个磁盘的一系列元数据，我们可以在kernel/fs.h中看到super block的数据结构

磁盘的第三个区域为log区，其对应的元数据为superblock中的nlog和logstart。这个区域存储着落盘的日志，每条日志对应一个block。实际上，日志本身是某个block经过一次完整的写操作之后的状态。在xv6系统中，为了维护好磁盘状态的一致性，对盘块的写操作暂时不会覆盖原来的盘块，而是将这个盘块作为一条日志存储在日志区，等待日志提交时再将日志区的盘块回写到相应的区域。这一部分的原理和内容将会在后面的日志层中介绍。

磁盘的第四个区域为inodes区，其对应的元数据为superblock中的inodestart和nblocks。每个文件都会对应着inode区的一个inode，每个inode记录着文件的元数据，例如文件类型、文件大小、盘块占据情况等。

磁盘的第五个区域为bitmap，其对应的元数据为superblock中的bmapstart。在xv6中使用位图来记录盘块的使用情况，相应的位图即被存放在了这个区域，为文件系统中盘块的分配与回收提供相应的支持。

之后就全是数据block了，数据block存储了文件的内容和目录的内容。

**磁盘格式化**
因为xv6使用的是虚拟机，所以是使用文件作为虚拟磁盘的
可以看一下mkfs/mkfs.c下的diamagnetic，这部分代码正好对应逻辑格式化（高级格式化）

**xv6是如何操作磁盘的**
virtio_disk.c的代码承担的是设备驱动程序的角色，文件系统通过调用virtio_disk_rw，实现对设备的写操作


**inode**
inode里到底存储了什么？

通常来说它有一个type字段，表明inode是文件还是目录。

nlink字段，也就是link计数器，用来跟踪究竟有多少文件名指向了当前的inode。

size字段，表明了文件数据有多少个字节。

不同文件系统中的表达方式可能不一样，不过在XV6中接下来是一些block的编号，例如编号0，编号1，等等。XV6的inode中总共有12个block编号。这些被称为direct block number。这12个block编号指向了构成文件的前12个block。举个例子，如果文件只有2个字节，那么只会有一个block编号0，它包含的数字是磁盘上文件前2个字节的block的位置。

之后还有一个indirect block number，它对应了磁盘上一个block，这个block包含了256个block number，这256个block number包含了文件的数据。所以inode中block number 0到block number 11都是direct block number，而block number 12保存的indirect block number指向了另一个block。



**目录**
在XV6中，这里的结构极其简单。每一个目录包含了directory entries，每一条entry都有固定的格式：
前2个字节包含了目录中文件或者子目录的inode编号，
接下来的14个字节包含了文件或者子目录名。


**xv6中inode创建**
在xv6的sysfile中包含了所有和文件系统相关的函数

分配inode在sysopen中
```C++
uint64 sys_open(void)
{
  char path[MAXPATH];
  int fd, omode;
  struct file *f;
  struct inode *ip;
  int n;

  if((n = argstr(0, path, MAXPATH)) < 0 || argint(1, &omode) < 0)
    return -1;

  begin_op();

  if(omode & O_CREATE){//O_CREATE表示创建文件的模式
    ip = create(path, T_FILE, 0, 0);//create函数会解析路径名并找到最后一个目录，查看文件是否存在，如果存在，那么就会返回错误，如果不存在就会调用ialloc分配一个inode节点
    if(ip == 0){
      end_op();
      return -1;
    }
  } else {
    if((ip = namei(path)) == 0){
      end_op();
      return -1;
    }
    ilock(ip);
    if(ip->type == T_DIR && omode != O_RDONLY){
      iunlockput(ip);
      end_op();
      return -1;
    }
  }

  if(ip->type == T_DEVICE && (ip->major < 0 || ip->major >= NDEV)){
    iunlockput(ip);
    end_op();
    return -1;
  }

  if((f = filealloc()) == 0 || (fd = fdalloc(f)) < 0){//分配一个文件结构体f，文件描述符fd
    if(f)
      fileclose(f);
    iunlockput(ip);
    end_op();
    return -1;
  }

  if(ip->type == T_DEVICE){
    f->type = FD_DEVICE;
    f->major = ip->major;
  } else {
    f->type = FD_INODE;
    f->off = 0;
  }
  f->ip = ip;
  f->readable = !(omode & O_WRONLY);
  f->writable = (omode & O_WRONLY) || (omode & O_RDWR);

  if((omode & O_TRUNC) && ip->type == T_FILE){
    itrunc(ip);
  }

  iunlock(ip);
  end_op();

  return fd;
}
```

```C++
static struct inode*
create(char *path, short type, short major, short minor)
{
  struct inode *ip, *dp;
  char name[DIRSIZ];

  if((dp = nameiparent(path, name)) == 0)
    return 0;

  ilock(dp);

  if((ip = dirlookup(dp, name, 0)) != 0){
    iunlockput(dp);
    ilock(ip);
    if(type == T_FILE && (ip->type == T_FILE || ip->type == T_DEVICE))
      return ip;
    iunlockput(ip);
    return 0;
  }

  if((ip = ialloc(dp->dev, type)) == 0)
    panic("create: ialloc");

  ilock(ip);
  ip->major = major;
  ip->minor = minor;
  ip->nlink = 1;
  iupdate(ip);

  if(type == T_DIR){  // Create . and .. entries.
    dp->nlink++;  // for ".."
    iupdate(dp);
    // No ip->nlink++ for ".": avoid cyclic ref count.
    if(dirlink(ip, ".", ip->inum) < 0 || dirlink(ip, "..", dp->inum) < 0)
      panic("create dots");
  }

  if(dirlink(dp, name, ip->inum) < 0)
    panic("create: dirlink");

  iunlockput(dp);

  return ip;
}
```

ialloc位于fs.c中

for循环遍历从1到sb.ninodes（超级块中定义的inode总数）的所有inode编号。
调用bread函数读取存储inode的磁盘块到内存缓冲区bp中。
根据inode编号计算在磁盘块中的具体位置，将该位置处的数据强制转换为dinode结构体指针dip。
检查dip指向的inode是否为空闲（type为0），如果是则说明该inode可以分配。
使用memset函数将该inode的内容清零，并将type设置为传入的type。
调用log_write函数将修改后的bp写回磁盘，标记该inode已分配。
调用brelse函数释放磁盘块缓冲区。
调用iget函数根据设备和inode编号获取inode指针，并返回给调用者。
```C++
struct inode*
ialloc(uint dev, short type)
{
  int inum;
  struct buf *bp;
  struct dinode *dip;

  for(inum = 1; inum < sb.ninodes; inum++){
    bp = bread(dev, IBLOCK(inum, sb));
    dip = (struct dinode*)bp->data + inum%IPB;
    if(dip->type == 0){  // a free inode
      memset(dip, 0, sizeof(*dip));
      dip->type = type;
      log_write(bp);   // mark it allocated on the disk
      brelse(bp);
      return iget(dev, inum);
    }
    brelse(bp);
  }
  panic("ialloc: no inodes");
}
```

这里有个有意思的问题，当多个进程同时调用create的时候会产生什么事情，两个进程会同时调用ialloc，然后首先调用bread，我们看一下bio.c中的bread
```C++
struct buf* bread(uint dev, uint blockno)//输入也是设别号和块号
{
  struct buf *b;

  b = bget(dev, blockno);
  if(!b->valid) {
    virtio_disk_rw(b, 0);
    b->valid = 1;
  }
  return b;
}
```
我们发现bread会首先调用bget,我们发现bget对访问进行了加锁
```C++
static struct buf* bget(uint dev, uint blockno)//参数是设备号和块号
{
  struct buf *b;

  acquire(&bcache.lock);

  // Is the block already cached?
  for(b = bcache.head.next; b != &bcache.head; b = b->next){
    if(b->dev == dev && b->blockno == blockno){
      b->refcnt++;//引用计数
      release(&bcache.lock);
      acquiresleep(&b->lock);
      return b;
    }
  }

  // Not cached.
  // Recycle the least recently used (LRU) unused buffer.
  for(b = bcache.head.prev; b != &bcache.head; b = b->prev){
    if(b->refcnt == 0) {
      b->dev = dev;
      b->blockno = blockno;
      b->valid = 0;
      b->refcnt = 1;
      release(&bcache.lock);
      acquiresleep(&b->lock);
      return b;
    }
  }
  panic("bget: no buffers");
}
```
**内存管理**
bread从磁盘上读取(dev, blockno)对应的磁盘块到buf->data中，bwrite将buf->data的内容回写到(dev, blockno)上，它们对设备的读写操作都是通过调用设备驱动代码所提供的virtio_disk_rw来实现的
**LRU置换算法**
buf的数量明显小于盘块的数量，因此缓冲池必须要有相应的置换算法，当已经没有未分配的缓冲块时，要选择重复利用一个已经没有进程引用的缓冲块。为了提高缓冲区的命中率，xv6选择了LRU置换算法，即优先淘汰掉那些最长时间未使用的缓冲块。
这部分代码在brelse  








